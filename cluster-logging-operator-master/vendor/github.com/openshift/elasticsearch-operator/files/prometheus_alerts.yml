---
"groups":
- "name": "logging_elasticsearch.alerts"
  "rules":
  - "alert": "ElasticsearchClusterNotHealthy"
    "annotations":
      "description": "Cluster {{ $labels.cluster }} health status has been RED for at least 2m. Cluster does not accept writes, shards may be missing or master node hasn't been elected yet."
      "summary": "Cluster health status is RED"
    "expr": |
      sum by (cluster) (es_cluster_status == 2)
    "for": "2m"
    "labels":
      "severity": "critical"
  - "alert": "ElasticsearchClusterNotHealthy"
    "annotations":
      "description": "Cluster {{ $labels.cluster }} health status has been YELLOW for at least 20m. Some shard replicas are not allocated."
      "summary": "Cluster health status is YELLOW"
    "expr": |
      sum by (cluster) (es_cluster_status == 1)
    "for": "20m"
    "labels":
      "severity": "warning"
  - "alert": "ElasticsearchBulkRequestsRejectionJumps"
    "annotations":
      "description": "High Bulk Rejection Ratio at {{ $labels.node }} node in {{ $labels.cluster }} cluster. This node may not be keeping up with the indexing speed."
      "summary": "High Bulk Rejection Ratio - {{ $value }}%"
    "expr": |
      round( bulk:reject_ratio:rate2m * 100, 0.001 ) > 5
    "for": "10m"
    "labels":
      "severity": "warning"
  - "alert": "ElasticsearchNodeDiskWatermarkReached"
    "annotations":
      "description": "Disk Low Watermark Reached at {{ $labels.node }} node in {{ $labels.cluster }} cluster. Shards can not be allocated to this node anymore. You should consider adding more disk to the node."
      "summary": "Disk Low Watermark Reached - disk saturation is {{ $value }}%"
    "expr": |
      sum by (cluster, instance, node) (
        round(
          (1 - (
            es_fs_path_available_bytes /
            es_fs_path_total_bytes
          )
        ) * 100, 0.001)
      ) > 85
    "for": "5m"
    "labels":
      "severity": "alert"
  - "alert": "ElasticsearchNodeDiskWatermarkReached"
    "annotations":
      "description": "Disk High Watermark Reached at {{ $labels.node }} node in {{ $labels.cluster }} cluster. Some shards will be re-allocated to different nodes if possible. Make sure more disk space is added to the node or drop old indices allocated to this node."
      "summary": "Disk High Watermark Reached - disk saturation is {{ $value }}%"
    "expr": |
      sum by (cluster, instance, node) (
        round(
          (1 - (
            es_fs_path_available_bytes /
            es_fs_path_total_bytes
          )
        ) * 100, 0.001)
      ) > 90
    "for": "5m"
    "labels":
      "severity": "high"
  - "alert": "ElasticsearchNodeDiskLowForSegmentMerges"
    "annotations":
      "description": "Free disk at {{ $labels.node }} node in {{ $labels.cluster }} cluster may be low for optimal segment merges"
      "summary": "Free disk may be low for optimal segment merges"
    "expr": |
      sum by (cluster, instance, node) (es_fs_path_free_bytes) /
      sum by (cluster, instance, node) (es_indices_store_size_bytes)
      < 0.5
    "for": "15m"
    "labels":
      "severity": "warning"
  - "alert": "ElasticsearchJVMHeapUseHigh"
    "annotations":
      "description": "JVM Heap usage on the node {{ $labels.node }} in {{ $labels.cluster }} cluster is {{ $value }}%."
      "summary": "JVM Heap usage on the node is high"
    "expr": |
      sum by (cluster, instance, node) (es_jvm_mem_heap_used_percent) > 75
    "for": "10m"
    "labels":
      "severity": "alert"
  - "alert": "AggregatedLoggingSystemCPUHigh"
    "annotations":
      "description": "System CPU usage on the node {{ $labels.node }} in {{ $labels.cluster }} cluster is {{ $value }}%"
      "summary": "System CPU usage is high"
    "expr": |
      sum by (cluster, instance, node) (es_os_cpu_percent) > 90
    "for": "1m"
    "labels":
      "severity": "alert"
  - "alert": "ElasticsearchProcessCPUHigh"
    "annotations":
      "description": "ES process CPU usage on the node {{ $labels.node }} in {{ $labels.cluster }} cluster is {{ $value }}%"
      "summary": "ES process CPU usage is high"
    "expr": |
      sum by (cluster, instance, node) (es_process_cpu_percent) > 90
    "for": "1m"
    "labels":
      "severity": "alert"

